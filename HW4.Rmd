---
title: "Untitled"
author: "Xiaoting Chen"
date: "2023-11-13"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Prep

Load library
```{r message=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(MASS)
library(optmatch)
# if choose fullmatching
library(sensitivityfull)
```


## 1. 

Consider question 1 from Homework 3 about the effect of being physically active on living longer. Use one of your matchings from Homework 3 (e.g., your pair matching) to perform a sensitivity analysis.

### (a) 
Up to what value of $\Gamma$ is there still evidence that being physically active causes you to live longer (under the significance level 0.05)?\


**Answer:**\
Out of the several matching methods in HW3, full matching methods achieved the best balance of covariates betweeen treated and control groups, thus I will proceed with full matching method and perform the sensitivity analysis.\

Firstly we construct the full matching dataset using the same methods in HW3. \

#### Data prep
```{r}
dat <- read.csv("nhanesi_class_dataset.csv")

# recode categorical confounders into numerical
lapply(dat[c("physically.inactive",'sex', "smoking.status", "race", "education", "working.last.three.months", 
             "married", "alcohol.consumption")], 
       unique)

dat <- dat %>%
  dplyr::select(-X) %>%
  mutate(physically.inactive = ifelse(physically.inactive==TRUE, 1, 0),
         sex = recode(sex, 'Female' = 1, 'Male' = 0),
         smoking.status = recode(smoking.status, "Never"=1,  "Current"=2, "Former"=3),
         race = recode(race, "Nonwhite"=0, "White"=1),
         education = recode(education, "0-8"=1, "9-11"=2, "12"=3, "College Grad"=4, "Some College"=5, "Missing"=9),
         working.last.three.months = ifelse(working.last.three.months==TRUE, 1, 0),
         married = ifelse(married==TRUE, 1, 0),
         alcohol.consumption = recode(alcohol.consumption, "Never"=1, "Just about everyday/everyday"=5, 
                                      "1-4 times per month"=3,
                                      "2+ times per week"=4,  "<1 time per month"=2))

```

Impute missing values in the data
```{r}
# check missingness
colSums(is.na(dat))

# impute the missingness in income.poverty.ratio and dietary.adequacy with mean value

dat <- dat %>%
  mutate(income.poverty.ratio = ifelse(is.na(income.poverty.ratio), 
                                       mean(income.poverty.ratio, na.rm = TRUE), income.poverty.ratio),
         dietary.adequacy = ifelse(is.na(dietary.adequacy),
                                   mean(dietary.adequacy, na.rm = TRUE), dietary.adequacy))
```

#### Fit a propensity score model
```{r}
propscore.model=glm(physically.inactive~.,family=binomial,x=TRUE,y=TRUE, data=dat[,-2]);
datatemp=drop_na(dat)
datatemp$outcome=datatemp$years.lived.since.1971.up.to.1992

# according to propscore.model result 
# consider income.poverty.ratio, working.last.three.months, married, dietary.adequacy 
# as prognostically important
Xmatmahal=subset(datatemp,select=c(income.poverty.ratio,working.last.three.months, married, dietary.adequacy ))
nocontrols.per.match=2

datatemp$treated=propscore.model$y
treated=datatemp$treated
datatemp$logit.ps=predict(propscore.model)

rownames(datatemp)=seq(1,nrow(datatemp),1) # Make the rownames in datatemp be 1:number of rows

# Function for computing rank based Mahalanobis distance. 
smahal=
  function(z,X){
    X<-as.matrix(X)
    n<-dim(X)[1]
    rownames(X)<-1:n
    k<-dim(X)[2]
    m<-sum(z)
    for (j in 1:k) X[,j]<-rank(X[,j])
    cv<-cov(X)
    vuntied<-var(1:n)
    rat<-sqrt(vuntied/diag(cv))
    cv<-diag(rat)%*%cv%*%diag(rat)
    out<-matrix(NA,m,n-m)
    Xc<-X[z==0,]
    Xt<-X[z==1,]
    rownames(out)<-rownames(X)[z==1]
    colnames(out)<-rownames(X)[z==0]
    library(MASS)
    icov<-ginv(cv)
    for (i in 1:m) out[i,]<-mahalanobis(Xc,Xt[i,],icov,inverted=T)
    out
  }

# Function for adding a propensity score caliper to a distance matrix dmat
# calipersd is the caliper in terms of standard deviation of the logit propensity scoe
addcaliper=function(dmat,z,logitp,calipersd=.2,penalty=1000){
  sd.logitp=sd(logitp)
  adif=abs(outer(logitp[z==1],logitp[z==0],"-"))
  adif=(adif-(calipersd*sd.logitp))*(adif>(calipersd*sd.logitp))
  dmat=dmat+adif*penalty
  dmat
}

# Matrix of covariates, excluding intercept
Xmat=propscore.model$x[,-1]

# Rank based Mahalanobis distance
distmat=smahal(datatemp$treated,Xmatmahal)
# Add caliper
distmat2=addcaliper(distmat,datatemp$treated,datatemp$logit.ps,calipersd=.5)

### Name the rows and columns of distance matrix by the subject numbers in treated
# Label the rows and columns of the distance matrix by the rownames in datatemp
rownames(distmat2)=rownames(datatemp)[datatemp$treated==1]
colnames(distmat2)=rownames(datatemp)[datatemp$treated==0]

```

#### Matching
```{r}
diff.propensity.score.mat=outer(datatemp$logit.ps[datatemp$treated==1],datatemp$logit.ps[datatemp$treated==0],"-")
distmat.propensity=abs(diff.propensity.score.mat)
# Label the rows and columns of the distance matrix by the rownames in datatemp
rownames(distmat.propensity)=rownames(datatemp)[datatemp$treated==1]
colnames(distmat.propensity)=rownames(datatemp)[datatemp$treated==0]

matchvec=fullmatch(distmat.propensity,data=datatemp)
datatemp$matchvec=matchvec
#stratumStructure(matchvec)
#effectiveSampleSize(matchvec)
```

#### Conduct sensitivity analysis
```{r}
# Aligned rank test sensitivity analysis
# One sided p-value with alternative being greater
# gamma is equal to Gamma=exp(gamma) in Paul's formulation
primary.sens.analysis=function(outcome,matchedset,treated,Gamma,alternative="greater"){
      # Compute means in each matched set
      matchedset.mean=tapply(outcome,matchedset,mean);
      # Compute residuals
      matchedset.mean.expand=matchedset.mean[matchedset];
      resids=outcome-matchedset.mean.expand;
      # Rank the residuals
      rankresids=rank(resids);
      # Test statistics = Sum of residuals in treatment group
      teststat=sum(rankresids[treated==1]);
      if(alternative=="greater"){
      # Compute mu.i.max and sigma.i.max.sq in each matched set i
      # Assumes matched sets are labeled 1,...,I
      nomatchedset=length(unique(matchedset));
      mu.i.max=rep(0,nomatchedset);
      visq=rep(0,nomatchedset);
      for(i in 1:nomatchedset){
          ranks.matchedseti=rankresids[matchedset==i];
          notreated.matchedseti=sum(treated[matchedset==i]);
      if(notreated.matchedseti==1){
          sort.ranks.matchedseti=sort(ranks.matchedseti);
          ni=length(ranks.matchedseti);
          muia=rep(0,ni-1);
          viasq=rep(0,ni-1);
          for(j in 1:(ni-1)){
            muia[j]=(sum(sort.ranks.matchedseti[1:j])+Gamma*sum(sort.ranks.matchedseti[(j+1):ni]))/(j+Gamma*(ni-j));
            viasq[j]=(sum(sort.ranks.matchedseti[1:j]^2)+Gamma*sum(sort.ranks.matchedseti[(j+1):ni]^2))/(j+Gamma*(ni-j))-muia[j]^2;
          }
          mu.i.max[i]=max(muia);
          visq[i]=max(viasq[which(muia==max(muia))]);
        }
      if(notreated.matchedseti>1){
          sort.ranks.matchedseti=sort(ranks.matchedseti,decreasing=TRUE);
          ni=length(ranks.matchedseti);
          muia=rep(0,ni-1);
          viasq=rep(0,ni-1);
          totalranksum.matchedset=sum(ranks.matchedseti);
          for(j in 1:(ni-1)){
            muicontrol=(sum(sort.ranks.matchedseti[1:j])+Gamma*sum(sort.ranks.matchedseti[(j+1):ni]))/(j+Gamma*(ni-j));
            muia[j]=totalranksum.matchedset-muicontrol
            viasq[j]=(sum(sort.ranks.matchedseti[1:j]^2)+Gamma*sum(sort.ranks.matchedseti[(j+1):ni]^2))/(j+Gamma*(ni-j))-muicontrol^2;
      }
          mu.i.max[i]=max(muia);
          visq[i]=max(viasq[which(muia==max(muia))]);
      
        }
      }
      pval=1-pnorm((teststat-sum(mu.i.max))/sqrt(sum(visq)));
    }
    
    if(alternative=="lesser"){
    # Compute mu.i.min and sigma.i.max.sq in each matched set i
    # Assumes matched sets are labeled 1,...,I
    nomatchedset=length(unique(matchedset));
    mu.i.min=rep(0,nomatchedset);
    visq=rep(0,nomatchedset);
    for(i in 1:nomatchedset){
        ranks.matchedseti=rankresids[matchedset==i];
        notreated.matchedseti=sum(treated[matchedset==i]);
    if(notreated.matchedseti==1){
        sort.ranks.matchedseti=sort(ranks.matchedseti);
        ni=length(ranks.matchedseti);
        muia=rep(0,ni-1);
        viasq=rep(0,ni-1);
        for(j in 1:(ni-1)){
          muia[j]=(sum(sort.ranks.matchedseti[1:j])+(1/Gamma)*sum(sort.ranks.matchedseti[(j+1):ni]))/(j+(1/Gamma)*(ni-j));
          viasq[j]=(sum(sort.ranks.matchedseti[1:j]^2)+(1/Gamma)*sum(sort.ranks.matchedseti[(j+1):ni]^2))/(j+(1/Gamma)*(ni-j))-muia[j]^2;
        }
        mu.i.min[i]=min(muia);
        visq[i]=max(viasq[which(muia==min(muia))]);
      }
    if(notreated.matchedseti>1){
        sort.ranks.matchedseti=sort(ranks.matchedseti,decreasing=TRUE);
        ni=length(ranks.matchedseti);
        muia=rep(0,ni-1);
        viasq=rep(0,ni-1);
        totalranksum.matchedset=sum(ranks.matchedseti);
        for(j in 1:(ni-1)){
          muicontrol=(sum(sort.ranks.matchedseti[1:j])+(1/Gamma)*sum(sort.ranks.matchedseti[(j+1):ni]))/(j+(1/Gamma)*(ni-j));
          muia[j]=totalranksum.matchedset-muicontrol
          viasq[j]=(sum(sort.ranks.matchedseti[1:j]^2)+(1/Gamma)*sum(sort.ranks.matchedseti[(j+1):ni]^2))/(j+(1/Gamma)*(ni-j))-muicontrol^2;
    }
        mu.i.min[i]=max(muia);
        visq[i]=max(viasq[which(muia==max(muia))]);
    
      }
    }
    pval=pnorm((teststat-sum(mu.i.min))/sqrt(sum(visq)));
    }
    
        pval;
}

```


```{r}
outcome=datatemp$outcome

treated=datatemp$treated
matchedset.index=substr(datatemp$matchvec,start=3,stop=10)
matchedset=as.numeric(matchedset.index)

upperP = c(primary.sens.analysis(outcome,matchedset,treated,Gamma=4),
            primary.sens.analysis(outcome,matchedset,treated,Gamma=5),
           primary.sens.analysis(outcome,matchedset,treated,Gamma=5.4),
           primary.sens.analysis(outcome,matchedset,treated,Gamma=5.5),
            primary.sens.analysis(outcome,matchedset,treated,Gamma=6),
            primary.sens.analysis(outcome,matchedset,treated,Gamma=7))
gamma = c(4,5,5.4,5.5,6,7)

sen_tab = data.frame(gamma, upperP)
sen_tab
```


**According to the sensitivity analysis result table, up to $\Gamma = 5.4$, there is still evidence that being physically active causes you to live longer. **



## 2. 

### (a) 
Construct a match with adequate balance and test whether having a deceased
father increases college attendance under the assumption of no unmeasured
confounding (you could consider several matches and choose the one you think is
best, but make sure to choose the match before testing the outcome to preserve the
blinding advantages of matching).

#### Data prep
```{r}
dat2 <- read.csv("educationaid7981.csv") 
dat2 = dat2[,-c(1,2)]

# check missingness in data
missing_values <- colSums(is.na(dat2))
print(missing_values)
```

#### Fit a propensity score model
```{r}
propscore.model=glm(f_dead ~.,family=binomial,x=TRUE,y=TRUE, data=dat2[,-10]);
datatemp=drop_na(dat2)
datatemp$outcome=datatemp$attend.college

# according to propscore.model result 
# consider faminc and incmiss
# as prognostically important
Xmatmahal=subset(datatemp,select=c(faminc, incmiss))

datatemp$treated=propscore.model$y
treated=datatemp$treated
datatemp$logit.ps=predict(propscore.model)

rownames(datatemp)=seq(1,nrow(datatemp),1) # Make the rownames in datatemp be 1:number of rows

# Function for computing rank based Mahalanobis distance. 
smahal=
  function(z,X){
    X<-as.matrix(X)
    n<-dim(X)[1]
    rownames(X)<-1:n
    k<-dim(X)[2]
    m<-sum(z)
    for (j in 1:k) X[,j]<-rank(X[,j])
    cv<-cov(X)
    vuntied<-var(1:n)
    rat<-sqrt(vuntied/diag(cv))
    cv<-diag(rat)%*%cv%*%diag(rat)
    out<-matrix(NA,m,n-m)
    Xc<-X[z==0,]
    Xt<-X[z==1,]
    rownames(out)<-rownames(X)[z==1]
    colnames(out)<-rownames(X)[z==0]
    library(MASS)
    icov<-ginv(cv)
    for (i in 1:m) out[i,]<-mahalanobis(Xc,Xt[i,],icov,inverted=T)
    out
  }

# Function for adding a propensity score caliper to a distance matrix dmat
# calipersd is the caliper in terms of standard deviation of the logit propensity scoe
addcaliper=function(dmat,z,logitp,calipersd=.2,penalty=1000){
  sd.logitp=sd(logitp)
  adif=abs(outer(logitp[z==1],logitp[z==0],"-"))
  adif=(adif-(calipersd*sd.logitp))*(adif>(calipersd*sd.logitp))
  dmat=dmat+adif*penalty
  dmat
}

# Matrix of covariates, excluding intercept
Xmat=propscore.model$x[,-1]

# Rank based Mahalanobis distance
distmat=smahal(datatemp$treated,Xmatmahal)
# Add caliper
distmat2=addcaliper(distmat,datatemp$treated,datatemp$logit.ps,calipersd=.5)

### Name the rows and columns of distance matrix by the subject numbers in treated
# Label the rows and columns of the distance matrix by the rownames in datatemp
rownames(distmat2)=rownames(datatemp)[datatemp$treated==1]
colnames(distmat2)=rownames(datatemp)[datatemp$treated==0]

```

#### Consider full matching
```{r}
diff.propensity.score.mat=outer(datatemp$logit.ps[datatemp$treated==1],datatemp$logit.ps[datatemp$treated==0],"-")
distmat.propensity=abs(diff.propensity.score.mat)
# Label the rows and columns of the distance matrix by the rownames in datatemp
rownames(distmat.propensity)=rownames(datatemp)[datatemp$treated==1]
colnames(distmat.propensity)=rownames(datatemp)[datatemp$treated==0]

matchvec=fullmatch(distmat.propensity,data=datatemp)
datatemp$matchvec=matchvec
#stratumStructure(matchvec)
#effectiveSampleSize(matchvec)
```

#### check balance

```{r}
# check balance

# Number the strata
matchedset.index=substr(matchvec,start=3,stop=10)
matchedset.index.numeric=as.numeric(matchedset.index)

# Calculate standardized difference before and after a full match
# Calculate standardized difference before and after a full match
# Drop observations with missing values from the calculations
# stratum.myindex should contain strata for each subject, 0 means a unit was not 
# matched
# Use harmonic mean weights
standardized.diff.harmonic.func=function(x,treatment,stratum.myindex,missing=rep(0,length(x))){
  xtreated=x[treatment==1 & missing==0];
  xcontrol=x[treatment==0 & missing==0];
  var.xtreated=var(xtreated);
  var.xcontrol=var(xcontrol);
  combinedsd=sqrt(.5*(var.xtreated+var.xcontrol));
  std.diff.before.matching=(mean(xtreated)-mean(xcontrol))/combinedsd;
  nostratum=length(unique(stratum.myindex))-1*max(stratum.myindex==0);
  if(max(stratum.myindex==0)==0){
    stratumlist=sort(unique(stratum.myindex))
  }
  if(max(stratum.myindex==0)==1){
    templist=sort(unique(stratum.myindex))
    stratumlist=templist[-1]
  }
  diff.in.stratum=rep(0,nostratum);
  number.in.stratum=rep(0,nostratum);
  harmonic.weight=rep(0,nostratum)
  for(i in 1:nostratum){
    if(sum(stratum.myindex==stratumlist[i] & treatment==1 & missing==0)==0 | sum(stratum.myindex==stratumlist[i] & treatment==0 & missing==0)==0){
      number.in.stratum[i]=0
    }
    if(sum(stratum.myindex==stratumlist[i] & treatment==1 & missing==0)>0 & sum(stratum.myindex==stratumlist[i] & treatment==0 & missing==0)>0){
      diff.in.stratum[i]=mean(x[stratum.myindex==stratumlist[i] & treatment==1 & missing==0])-mean(x[stratum.myindex==stratumlist[i] & treatment==0 & missing==0]);
      number.in.stratum[i]=sum(stratum.myindex==stratumlist[i])
      harmonic.weight[i]=1/(.5/sum(stratum.myindex==stratumlist[i] & treatment==1)+.5/sum(stratum.myindex==stratumlist[i] & treatment==0))
    }
  }
  std.diff.after.matching=(sum(harmonic.weight*diff.in.stratum)/sum(harmonic.weight))/combinedsd;
  list(std.diff.before.matching=std.diff.before.matching,std.diff.after.matching=std.diff.after.matching);
}

# Covariates used in propensity score model
Xmat=propscore.model$x;


Xmat.without.missing=Xmat

# Calculate the standardized differences
std.diff.before=rep(0,ncol(Xmat.without.missing));
std.diff.after=rep(0,ncol(Xmat.without.missing));
names(std.diff.before)=names(Xmat[1,]);
names(std.diff.after)=names(Xmat[1,]);
for(i in 1:ncol(Xmat.without.missing)){
missing.temp=is.na(Xmat.without.missing[,i])
temp.stand.diff=standardized.diff.harmonic.func(Xmat.without.missing[,i],datatemp$treated,matchedset.index.numeric,missing.temp);
std.diff.before[i]=temp.stand.diff$std.diff.before.matching;
std.diff.after[i]=temp.stand.diff$std.diff.after.matching;
}

# Rename std.diff.before and std.diff.after to shorter names sd.bf and sd.af
# and use digits option to be able to columns of std.diff.before and 
# std.diff.after in one row
sd.bf=std.diff.before
sd.af=std.diff.after

# love plot
abs.sd.bf=abs(sd.bf[-1])
abs.sd.af=abs(sd.af[-1])
covariates=names(sd.bf[-1])
plot.dataframe=data.frame(abs.stand.diff=c(abs.sd.bf,abs.sd.af),covariates=rep(covariates,2),type=c(rep("Before",length(covariates)),rep("After",length(covariates))))
ggplot(plot.dataframe,aes(x=abs.stand.diff,y=covariates))+geom_point(size=5,aes(shape=factor(type)))+scale_shape_manual(values=c(4,1))+geom_vline(xintercept=c(.1,.2),lty=2)
```
**According to the love plot, the balance given by full matching method is quite ideal, thus we proceed the inference using the full matching pseudo dataset. In the given case where the outcome is binary and matching method is full matching, we use Mantel-Haenszel test to test the Fisher sharp null of no treatment effect.**


#### Inference
```{r}
outcome=datatemp$outcome
treated=datatemp$treated
matchedset.index=substr(datatemp$matchvec,start=3,stop=10)
matchedset.index.numeric=as.numeric(matchedset.index)

```

```{r}
# Put data into format for senfmCI function
library(sensitivityfull)
stratum.myindex=matchedset.index.numeric
nostratum=length(unique(stratum.myindex))-1*max(stratum.myindex==0);
if(max(stratum.myindex==0)==0){
  stratumlist=sort(unique(stratum.myindex))
}
if(max(stratum.myindex==0)==1){
  templist=sort(unique(stratum.myindex))
  stratumlist=templist[-1]
}
treated1=rep(0,nostratum)
stratumsize=rep(0,nostratum)
for(i in 1:nostratum){
  stratumsize[i]=sum(stratum.myindex==stratumlist[i])
}

y=matrix(rep(NA,nostratum*max(stratumsize)),nrow=nostratum)
for(i in 1:nostratum){
  no.treated.in.stratum=sum(stratum.myindex==stratumlist[i] & datatemp$treated==1)
  no.control.in.stratum=sum(stratum.myindex==stratumlist[i] & datatemp$treated==0)
  treated.in.stratum=which(stratum.myindex==stratumlist[i] & datatemp$treated==1)
  control.in.stratum=which(stratum.myindex==stratumlist[i] & datatemp$treated==0)  
  if(no.treated.in.stratum==1){
    y[i,1]=datatemp$outcome[treated.in.stratum]
    y[i,2:(no.control.in.stratum+1)]=datatemp$outcome[control.in.stratum]
    treated1[i]=1
  }
  if(no.treated.in.stratum>1){
    y[i,1]=datatemp$outcome[control.in.stratum]
    y[i,2:(no.treated.in.stratum+1)]=datatemp$outcome[treated.in.stratum]
    treated1[i]=0
  }
}

treated1=as.logical(treated1)
senfmCI(y,treated1)    

```
**Acoording to the 95% CI for the treatment effect estimate [0.001, 0.186], assuming no unmeasured confounding, there is evidence that having a deceased father increases college attendance at alpha = 0.05 level.**


### (b) 
Conduct a sensitivity analysis to address concerns about unmeasured confounding.
```{r}
library(sensitivity2x2xk)

alldata=matrix(c(sum(outcome[treated==1]),
                    sum(outcome[matchedset.index.numeric]),
                    sum((1-outcome) [treated==1]),
                    sum((1-outcome)[matchedset.index.numeric])),
                  2,2)
 
rownames(alldata)=c("T","C") 
colnames(alldata)=c("Outcome=1","Outcome=0")

mh(alldata,Gamma=0.8)
```

**For gamma up to 0.8, there is still evidence that having a deceased father increases college attendance**


